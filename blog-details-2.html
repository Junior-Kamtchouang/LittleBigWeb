<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <title>Blog Details - Little Big Web</title>
    <meta name="description" content="">
    <meta name="keywords" content="">

    <!-- Favicons -->
    <!--  <link rel="apple-touch-icon" sizes="180x180" href="assets/img/LBW-Blaue-Logo.png">-->
    <link href="assets/img/favicon-lbw.ico" rel="shortcut icon" type="image/x-icon" />
    <link href="assets/img/favicon.ico" rel="shortcut icon" type="image/x-icon" />
    <link href="assets/img/favicon%20(1).ico" rel="shortcut icon" type="image/x-icon" />" href="assets/img/LBW-Blaue-Logo.png" type="image/png">

    <!-- Fonts -->
    <link href="https://fonts.googleapis.com" rel="preconnect">
    <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Raleway:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">

    <!-- Vendor CSS Files -->
    <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
    <link href="assets/vendor/aos/aos.css" rel="stylesheet">
    <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
    <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

    <!-- Main CSS File -->
    <link href="assets/css/main.css" rel="stylesheet">


</head>

<body class="blog-details-page">

<header id="header" class="header d-flex align-items-center fixed-top">
    <div class="container-fluid container-xl position-relative d-flex align-items-center justify-content-between">

        <a href="index.html" class="logo d-flex align-items-center">

            <h1 class="sitename">Little Big Web</h1>
        </a>

        <nav id="navmenu" class="navmenu">
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="service-details.html">Services</a></li>
                <li><a href="portfolio-details.html">Portfolio</a></li>
                <li><a href="blog.html">Blog</a></li>
                <li><a href="index.html#contact">Contact</a></li>
                <a class="btn-get-started"  href="#">Buchen</a>
            </ul>
            <i class="mobile-nav-toggle d-xl-none bi bi-list"></i>
        </nav>

    </div>
</header>
<main class="main">

    <!-- Page Title -->
    <div class="page-title dark-background" data-aos="fade" style="background-image: url(assets/img/page-title-background.jpg);">
        <div class="container position-relative">
<!--            <img src="assets/img/LBW-Blaue-Logo.png" alt="Little-Big-Web-Logo">-->
            <img src="assets/img/favicon-lbw.ico" alt="Little-Big-Web-Logo">

            <h1>Blog Details</h1>
            <nav class="breadcrumbs">
                <ol>
                    <li><a href="index.html">Home</a></li>
                    <li class="current">Blog Details</li>
                </ol>
            </nav>
        </div>
    </div><!-- End Page Title -->

    <div class="container">
        <div class="row">

            <div class="col-lg-8">
                <!-- Blog Details Section -->
                <section id="blog-details" class="blog-details section">
                    <div class="container">
                        <article class="article">
                            <div class="post-img">
                                <img src="assets/img/blog/blog-neural-networks.jpg" alt="" class="img-fluid">
                            </div>
                            <h1 class="title">Künstliche Neuronale Netze (KNN) im Maschinellen Lernen verstehen</h1>

                            <p>Künstliche neuronale Netze (KNN) sind Modelle, die auf der Struktur und Funktionsweise des menschlichen Gehirns basieren. Sie ermöglichen es, Muster in Daten zu erkennen, und spielen eine Schlüsselrolle im maschinellen Lernen. In diesem Artikel gehen wir auf die Funktionsweise von KNNs, mathematische Zusammenhänge und wichtige Konzepte wie Aktivierungsfunktionen, Fehlerfunktionen, Gradientabstieg, Backpropagation und Overfitting ein.</p>

                            <h2 class="title">1. Was sind künstliche neuronale Netze und wie funktionieren sie?</h2>
                            <p>Ein künstliches neuronales Netz (KNN) besteht aus mehreren Schichten miteinander verbundener Neuronen und ist so strukturiert, dass es Daten durch "Trainieren" analysiert und klassifiziert.</p>

                            <h2 class="title">Ziel und Aufbau von Künstlichen Neuronalen Netzen</h2>
                            <p>Das Ziel von KNNs ist es, Daten zu analysieren und Muster zu erkennen, die für traditionelle Algorithmen schwer fassbar sind. Ein KNN lernt durch Trainingsdaten, Muster zu erkennen und Vorhersagen oder Klassifikationen zu treffen.</p>

                            <h3 class="title">Grundaufbau und Funktionsweise</h3>
                            <ul>
                                <li><strong>Eingabeschicht (Input Layer):</strong> Die Eingabeschicht nimmt die Daten (z. B. Bildpixel oder Texteigenschaften) auf und leitet sie an die versteckten Schichten weiter.</li>
                                <li><strong>Versteckte Schichten (Hidden Layers):</strong> Diese Schichten analysieren die Daten und extrahieren relevante Merkmale.</li>
                                <li><strong>Ausgabeschicht (Output Layer):</strong> Hier wird die endgültige Entscheidung oder Vorhersage getroffen, z. B. die Klassifizierung eines Bildes.</li>
                            </ul>

                            <div class="example">
                                <h7 class="title">Beispiel:</h7>
                                <p>In einer Spam-Erkennungsanwendung analysiert die Eingabeschicht die Wörter in einer E-Mail. Die versteckten Schichten erkennen häufige Spam-Muster, und die Ausgabeschicht klassifiziert die E-Mail als "Spam" oder "Nicht-Spam".</p>
                            </div>

                            <h2 class="title">Arten des Lernens im Maschinellen Lernen</h2>
                            <p>Maschinelles Lernen besteht aus verschiedenen Lernarten, die jeweils auf spezifische Ziele und Anwendungen ausgerichtet sind. Diese Lernarten bilden die Grundlage für die KNN-Trainingsmethoden.</p>

                            <h4>1. Überwachtes Lernen</h4>
                            <p><strong>Ziel:</strong> Das Modell lernt, basierend auf Eingabedaten und den zugehörigen Ausgabedaten (Labels), korrekte Vorhersagen zu treffen.</p>
                            <p><strong>Vorgehen:</strong> Das Modell wird mit gelabelten Daten (z. B. "Spam" oder "Nicht-Spam") trainiert, um die Beziehung zwischen Eingabe und gewünschter Ausgabe zu lernen.</p>
                            <div class="example">
                                <h5>Beispiel:</h5>
                                <p>Gesichtserkennungssysteme lernen anhand von Bilddaten, welche Merkmale einem bestimmten Gesicht zugeordnet werden und erkennen Personen daraufhin in neuen Bildern.</p>
                            </div>

                            <h4>2. Unüberwachtes Lernen</h4>
                            <p><strong>Ziel:</strong> Das Modell soll Muster und Strukturen in den Daten erkennen, ohne dass es vorher definierte Ausgaben (Labels) gibt.</p>
                            <p><strong>Vorgehen:</strong> Das Modell analysiert die Daten und gruppiert ähnliche Datenpunkte automatisch in Cluster oder entdeckt Anomalien.</p>
                            <div class="example">
                                <h5>Beispiel:</h5>
                                <p>Kunden-Segmentierung im Marketing: Ein unüberwachtes Lernmodell kann Kunden automatisch in Gruppen einteilen, basierend auf ihrem Verhalten, ohne dass jede Gruppe vorab definiert wurde.</p>
                            </div>

                            <h4>3. Bestärkendes Lernen</h4>
                            <p><strong>Ziel:</strong> Ein Agent soll durch Versuch und Irrtum lernen und dabei belohnt werden, wenn er die richtige Entscheidung trifft, um eine optimale Strategie zu entwickeln.</p>
                            <p><strong>Vorgehen:</strong> Der Agent interagiert mit seiner Umgebung und erhält Belohnungen oder Bestrafungen, je nachdem, ob seine Entscheidungen richtig oder falsch waren.</p>
                            <div class="example">
                                <h5 >Beispiel:</h5>
                                <p>Ein Roboter, der lernt, Hindernisse zu vermeiden und seine Belohnung maximiert, indem er den besten Weg wählt.</p>
                            </div>

                            <h4>4. Semi-überwachtes Lernen</h4>
                            <p><strong>Ziel:</strong> Kombination von gelabelten und ungelabelten Daten, um das Modell effizienter zu trainieren und aus beiden Arten von Daten zu lernen.</p>
                            <p><strong>Vorgehen:</strong> Ein Teil der Daten hat Labels, während der andere Teil unlabelt ist. Das Modell lernt durch beide Datentypen und nutzt unüberwachte Muster, um die Vorhersagen zu verbessern.</p>

                            <h2 class="title">Klassifikation, Clustering und Lineare Regression</h2>

                            <h4>Klassifikation</h4>
                            <p><strong>Ziel:</strong> Ein Klassifikationsmodell teilt Daten in vordefinierte Klassen ein, wie "Spam" oder "Nicht-Spam".</p>
                            <p><strong>Vorgehen:</strong> Das Modell analysiert die Merkmale und trifft anhand des Trainingsdatensatzes eine Entscheidung für eine der vordefinierten Klassen.</p>
                            <div class="example">
                                <h5>Beispiel:</h5>
                                <p>Ein medizinisches System, das Röntgenbilder als "Gesund" oder "Krank" klassifiziert.</p>
                            </div>

                            <h4>Clustering</h4>
                            <p><strong>Ziel:</strong> Ähnliche Datenpunkte automatisch in Gruppen (Cluster) zu gruppieren.</p>
                            <p><strong>Vorgehen:</strong> Das Modell erkennt Muster und teilt die Daten in Cluster auf, ohne vorherige Labels. Diese Methode ist besonders nützlich in der Datenexploration.</p>
                            <div class="example">
                                <h5>Beispiel:</h5>
                                <p>Segmentierung von Kunden in Gruppen für gezielte Marketingkampagnen.</p>
                            </div>

                            <h4>Lineare Regression</h4>
                            <p><strong>Ziel:</strong> Vorhersage einer kontinuierlichen Zielvariablen basierend auf Eingabedaten.</p>
                            <p><strong>Vorgehen:</strong> Das Modell lernt eine lineare Beziehung zwischen Eingangs- und Zielvariable, um zukünftige Werte vorherzusagen.</p>
                            <div class="example">
                                <h5>Beispiel:</h5>
                                <p>Vorhersage des Verkaufspreises eines Hauses basierend auf Größe, Lage und Zustand.</p>
                            </div>

                            <h3 class="title">KNN Architektur und Lernprinzipien</h3>
                            <p>Künstliche neuronale Netze bestehen aus miteinander verbundenen Neuronen, die in drei Schichten strukturiert sind. Jede Schicht spielt eine Rolle bei der Verarbeitung der Informationen und trägt zur Gesamtvorhersage bei.</p>


                            <h2 class="title">Ähnlichkeiten und Unterschiede zu echten neuronalen Netzen</h2>
                                <h4>1. Struktur</h4>
                                <p><strong>Echte neuronale Netze:</strong> Das menschliche Gehirn besteht aus Milliarden von Neuronen, die komplex miteinander verbunden sind. Diese Neuronen kommunizieren über elektrische und chemische Signale, was die Verarbeitung von Informationen ermöglicht.</p>
                                <p><strong>Künstliche neuronale Netze:</strong> In KNNs besteht die Netzstruktur aus "Neuronen" in Schichten (Input, Hidden, Output), wobei jedes künstliche Neuron einfache mathematische Berechnungen durchführt. Die Schichten und Verbindungen sind jedoch vereinfacht, und die Anzahl der "Neuronen" ist deutlich geringer.</p>

                                <h4>2. Signalverarbeitung</h4>
                                <p><strong>Echte neuronale Netze:</strong> Neuronen kommunizieren durch das Feuern von Aktionspotentialen und die Freisetzung von Neurotransmittern. Diese Kommunikation ist sowohl elektrisch als auch chemisch und findet auf sehr komplexe Weise statt, wobei unterschiedliche Frequenzen und chemische Signale eine Rolle spielen.</p>
                                <p><strong>Künstliche neuronale Netze:</strong> In KNNs wird die Information als numerische Werte durch das Netz propagiert. Aktivierungsfunktionen simulieren das "Feuern" von Neuronen, wobei die Aktivierung von mathematischen Funktionen wie Sigmoid oder ReLU abgebildet wird. Die Verarbeitung ist rein mathematisch und folgt deterministischen Regeln.</p>

                                <h4>3. Lernprozesse</h4>
                                <p><strong>Echte neuronale Netze:</strong> Lernen und Gedächtnis im Gehirn entstehen durch neuronale Plastizität, also die Fähigkeit, Verbindungen zwischen Neuronen dynamisch zu verstärken oder abzuschwächen. Dies erfolgt über komplexe biochemische Mechanismen und Synapsenbildung.</p>
                                <p><strong>Künstliche neuronale Netze:</strong> Lernen erfolgt durch die Anpassung der Verbindungsgewichte zwischen den künstlichen Neuronen, meist durch Backpropagation und Optimierungsverfahren wie Gradientenabstieg. Es handelt sich um einen viel einfacheren, algorithmischen Prozess ohne biologische Entsprechungen.</p>

                                <h4>4. Parallelität und Anpassungsfähigkeit</h4>
                                <p><strong>Echte neuronale Netze:</strong> Das Gehirn verarbeitet Informationen extrem parallel, was eine hohe Geschwindigkeit und Effizienz ermöglicht. Zudem kann das Gehirn unglaublich flexibel auf unterschiedliche Reize reagieren und ist lernfähig, auch mit wenig Information.</p>
                                <p><strong>Künstliche neuronale Netze:</strong> Während einige KNN-Modelle parallelisierte Verarbeitungsprozesse unterstützen, sind sie bei weitem nicht so flexibel und effizient wie das Gehirn. KNNs benötigen oft riesige Mengen an Daten und Rechenleistung, um zu lernen und gute Ergebnisse zu erzielen.</p>

                                <h4>5. Repräsentation und Abstraktion</h4>
                                <p><strong>Echte neuronale Netze:</strong> Das Gehirn bildet Assoziationen, Emotionen und Erinnerungen, die auf biologischen Prozessen und einer Vielzahl von internen Zuständen beruhen, die nicht direkt messbar sind.</p>
                                <p><strong>Künstliche neuronale Netze:</strong> In KNNs handelt es sich um numerische Werte und statistische Mustererkennung. Sie "verstehen" die Daten nicht in menschlichem Sinne, sondern identifizieren lediglich Muster, die sie aus den Trainingsdaten gelernt haben.</p>

                                <h4>Fazit</h4>
                                <p>Die Ähnlichkeit zwischen künstlichen und echten neuronalen Netzen beschränkt sich auf eine sehr grundlegende strukturelle Inspiration. KNNs sind nützlich für bestimmte maschinelle Lernaufgaben, aber sie sind keine Replikationen des Gehirns. Fortschritte in der Neurowissenschaft und Informatik könnten zukünftige Modelle jedoch näher an die biologische Komplexität heranführen.</p>


                            <h3 class="title">Aufbau eines KNN: Feed-Forward-Netzwerke</h3>
                            <p><strong>Ziel:</strong> Feedforward-Neuronale Netze sind eine der einfachsten Formen von neuronalen Netzen. Ihr Ziel ist es, Eingabedaten zu verarbeiten und zu einer Ausgabe zu gelangen, ohne dass dabei Informationen zurückfließen.</p>
                            <p><strong>Vorgehen:</strong> Die Daten werden in einem Feedforward-Netz nur in eine Richtung weitergegeben – von der Eingabeschicht über die versteckten Schichten zur Ausgabeschicht. Es gibt also keine Rückkopplung oder „Loops“ im Netzwerk.
                            <ul>
                                <li><strong>Eingabeschicht:</strong> Nimmt Rohdaten (z.B. Bildpixel) auf.</li>
                                <li><strong>Versteckte Schichten:</strong> Verarbeiten die Eingaben durch gewichtete Summen und Aktivierungsfunktionen, um Muster zu extrahieren.</li>
                                <li><strong>Ausgabeschicht:</strong> Gibt die Vorhersage oder Klassifikation aus.</li>
                            </ul>
                            </p>
                            <p><strong>Beispiel:</strong> Stell dir vor, du möchtest ein Bildklassifizierungsnetzwerk bauen, das zwischen Katzen und Hunden unterscheidet. Die Pixelwerte des Bildes (Eingabedaten) fließen durch die Schichten des Netzes, werden in jeder Schicht weiterverarbeitet und enden schließlich in der Ausgabeschicht, die eine Entscheidung trifft (z.B. „Katze“ oder „Hund“). Der gesamte Prozess ist ein „Durchlauf“ durch das Netzwerk ohne Rücksprung, daher „Feedforward“.</p>

                            <h4 class="title">Mathematischer Zusammenhang</h4>
                            <p> Jedes Neuron berechnet die gewichtete Summe seiner Eingaben und wendet eine Aktivierungsfunktion an:</p>
                            <p><code>z = w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + ... + w<sub>n</sub>x<sub>n</sub> + b</code></p>
                            <p>Hierbei sind <code>w</code> die Gewichte, <code>x</code> die Eingabewerte und <code>b</code> der Bias. Die Aktivierungsfunktion entscheidet dann, ob das Neuron "feuert".</p>

                            <h3 class="title">Aktivierungsfunktionen und ihre mathematische Bedeutung</h3>
                            <p>Aktivierungsfunktionen sind entscheidend für die nicht-lineare Verarbeitung in KNNs. Sie ermöglichen dem Netzwerk, komplexe Zusammenhänge zu lernen:</p>
                            <ul>
                                <li><strong>Heaviside:</strong> Gibt 0 oder 1 zurück, je nach Schwellenwert (diskrete Aktivierung).</li>
                                <li><strong>Sigmoid:</strong> S-förmige Kurve, die Werte zwischen 0 und 1 skaliert, nützlich für Wahrscheinlichkeitsberechnungen:</p>

                                <li><strong>Tanh:</strong> Skaliert Werte zwischen -1 und 1, nützlich für zentrierte Daten:</p>

                                <li><strong>ReLU:</strong> Gibt nur positive Werte zurück (), was sparsames Lernen fördert.</li>
                                <li><strong>Softmax:</strong> Konvertiert Ausgaben in Wahrscheinlichkeiten für Klassifikationsprobleme:</p>
                                    <p></p>
                            </ul>
                            <p>Die Aktivierungsfunktionen in neuronalen Netzen helfen dabei, komplexe und nichtlineare Beziehungen in Daten zu erfassen und sicherzustellen, dass das Netz nützliche, differenzierte Informationen lernt. Jede Aktivierungsfunktion hat eine eigene mathematische Form und Besonderheiten, die sie für verschiedene Arten von Aufgaben geeignet machen. Hier sind die mathematischen Zusammenhänge der von dir genannten Aktivierungsfunktionen:</p>

                            <h4>1. Heaviside-Funktion (Schritt-Funktion)</h4>
                            <p><strong>Definition:</strong> Die Heaviside-Funktion ist eine einfache binäre Aktivierungsfunktion, die einen Schritt anzeigt, indem sie für positive Werte 1 und für negative Werte 0 zurückgibt.</p>
                            <p><strong>Mathematisch:</strong><br>
                                $$H(x) = \begin{cases}
                                1 & \text{wenn } x \geq 0 \\
                                0 & \text{wenn } x < 0
                                \end{cases}$$
                            </p>
                            <p><strong>Verwendung:</strong> Wegen ihrer binären Natur wird sie selten in neuronalen Netzen verwendet, da sie keine Differenzierbarkeit bietet (ein Problem für das Training). Sie findet eher Anwendung in der Logik oder in Schwellenwertmodellen.</p>

                            <h4>2. Tanh-Funktion (Hyperbolischer Tangens)</h4>
                            <p><strong>Definition:</strong> Die Tanh-Funktion ist eine glatte, S-förmige Funktion, die Werte zwischen -1 und 1 ausgibt. Sie ist der Sigmoid-Funktion ähnlich, zentriert sich jedoch bei 0 und eignet sich daher besser für Probleme, bei denen positive und negative Ausgaben relevant sind.</p>
                            <p><strong>Mathematisch:</strong><br>
                                <code>tanh(z) = (e<sup>z</sup> - e<sup>-z</sup>) / (e<sup>z</sup> + e<sup>-z</sup>)</code>
                            </p>

                            <p><strong>Verwendung:</strong> Sie ist hilfreich, wenn Daten sowohl positive als auch negative Werte haben und die Aktivierung zentriert sein sollte. Dies kann zu einer besseren Stabilität im Training führen als die Sigmoid-Funktion.</p>

                            <h4>3. Sigmoid-Funktion</h4>
                            <p><strong>Definition:</strong> Die Sigmoid-Funktion ist eine S-förmige (sigmoidale) Funktion, die Ausgaben zwischen 0 und 1 hat. Sie eignet sich für Klassifikationsaufgaben, bei denen Wahrscheinlichkeiten berechnet werden, da ihre Ausgabe wie eine Wahrscheinlichkeit interpretiert werden kann.</p>
                            <p><strong>Mathematisch:</strong><br><code>σ(z) = 1 / (1 + e<sup>-z</sup>)</code></p>
                            <p><strong>Verwendung:</strong> Sie wird oft in der letzten Schicht für binäre Klassifikationen verwendet, da sie einen glatten Übergang von 0 zu 1 bietet. Der Nachteil ist jedoch das sogenannte „Vanishing Gradient Problem“, bei dem große oder kleine Werte in ihrer Ableitung fast 0 ergeben, was das Lernen verlangsamt.</p>

                            <h4>4. ReLU-Funktion (Rectified Linear Unit)</h4>
                            <p><strong>Definition:</strong> Die ReLU-Funktion ist eine der am häufigsten verwendeten Aktivierungsfunktionen in neuronalen Netzen, insbesondere für tiefe Netze. Sie gibt alle negativen Werte als 0 und alle positiven Werte als \(x\) selbst zurück.</p>
                            <p><strong>Mathematisch:</strong><br>
                                <code>f(z) = max(0, z)</code>
                            </p>
                            <p><strong>Verwendung:</strong> Sie ist ideal für tiefe Netze, da sie das Vanishing Gradient Problem mildert. Allerdings gibt es bei ReLU das „Dying ReLU Problem“, bei dem einige Neuronen aufgrund ihrer konstanten 0-Ausgabe inaktiv werden können. Hierzu gibt es Varianten wie Leaky ReLU.</p>

                            <h4>5. Softmax-Funktion</h4>
                            <p><strong>Definition:</strong> Die Softmax-Funktion wird typischerweise in der Ausgabeschicht von Klassifikationsnetzwerken verwendet, wenn mehrere Klassen vorhergesagt werden. Sie skaliert die Ausgaben so, dass sie eine Wahrscheinlichkeitsverteilung über Klassen ergeben.</p>
                            <p><strong>Mathematisch:</strong> Für einen Vektor \(z = (z_1, z_2, \ldots, z_n)\) berechnet die Softmax-Funktion den Wert für jede Komponente \(i\) als:<br>
                                <code>softmax(z<sub>i</sub>) = e<sup>z<sub>i</sub></sup> / Σ e<sup>z<sub>j</sub></sup></code>
                            </p>
                            <p><strong>Verwendung:</strong> Softmax wird für Multi-Klassen-Klassifikationen verwendet, da sie jeder Ausgabe eine Wahrscheinlichkeit zuweist, die Summe der Wahrscheinlichkeiten jedoch stets 1 ergibt.</p>


                            <h3 class="title"> Der Trainingsprozess von KNN</h3>
                            <p>Das Ziel des Trainings ist es, ein Modell zu erstellen, das verlässliche Vorhersagen auf neuen Daten trifft. Hierbei wird der Fehler minimiert:</p>

                            <h3 class="title">Fehlerfunktion und Zielfunktion</h3>
                            <p>Die Fehlerfunktion (z.B. Mean Squared Error für Regression, Cross-Entropy für Klassifikation) misst den Unterschied zwischen der vorhergesagten und der tatsächlichen Ausgabe. Ziel ist die Minimierung dieser Fehlerfunktion:</p>
                            <p><code>MSE = (1/n) Σ (y<sub>pred</sub> - y<sub>true</sub>)<sup>2</sup></code></p>

                            <h4 class="title">Gradientenberechnung und Gradientabstieg</h4>
                            <p>Der Gradient beschreibt die Steigung der Fehlerfunktion in Bezug auf die Gewichte. Der Gradientabstieg passt die Gewichte so an, dass der Fehler minimiert wird:</p>
                            <p><code>w = w - η * ∇E</code></p>
                            <p>Hierbei ist <code>η</code> die Lernrate und <code>∇E</code> der Gradient des Fehlers.</p>

                            <h4 class="title">Backpropagation (Rückpropagation)</h4>
                            <p>Backpropagation berechnet den Fehler in der Ausgabeschicht und leitet ihn schrittweise zurück durch das Netzwerk. So kann das Modell lernen, indem es Gewichte anpasst:</p>
                            <p>Durch die Kettenregel der Differentiation wird der Fehler von der Ausgabeschicht zur Eingabeschicht weitergeleitet und bei jeder Schicht die Gewichte angepasst.</p>

                            <div class="example">
                                <h7 class="title">Beispiel:</h7>
                                <p>Ein Modell, das eine Katze als Hund klassifiziert hat, passt die Gewichte so an, dass bei ähnlichen Daten das Ergebnis "Katze" wahrscheinlicher wird.</p>
                            </div>

                            <h3 class="title">Optimierung und Hyperparameter im Training</h3>
                            <p>Hyperparameter, wie Lernrate und Epochenzahl, beeinflussen das Training:</p>
                            <ul>
                                <li><strong>Lernrate:</strong> Bestimmt, wie stark die Gewichte bei jedem Schritt angepasst werden.</li>
                                <li><strong>Epochen:</strong> Anzahl der Durchläufe über den gesamten Datensatz.</li>
                            </ul>

                            <h3 class="title">Overfitting und Generalisierung</h3>
                            <p>Overfitting tritt auf, wenn das Modell sich zu stark an die Trainingsdaten anpasst und neue Daten schlecht vorhersagt.</p>

                            <h3 class="title">Methoden zur Vermeidung von Overfitting</h3>
                            <ul>
                                <li><strong>Regularisierung:</strong> Bestraft große Gewichtswerte und reduziert die Komplexität.</li>
                                <li><strong>Dropout:</strong> Deaktiviert zufällig Neuronen während des Trainings, um Überanpassung zu vermeiden.</li>
                                <li><strong>Cross-Validation:</strong> Nutzt verschiedene Datensätze für eine bessere Generalisierung.</li>
                            </ul>

                            <h3 class="title">Zusammenfassung</h3>
                            <p>Künstliche neuronale Netze sind mächtige Werkzeuge für das maschinelle Lernen. Durch Training und Optimierung kann ein Modell lernen, komplexe Muster in Daten zu erkennen. Die Einbindung mathematischer Funktionen und sorgfältige Anpassung von Hyperparametern führt zu Modellen, die präzise und zuverlässig arbeiten.</p>

                            <div class="meta-top">
                                <ul>
                                    <li class="d-flex align-items-center"><i class="bi bi-person"></i> <a href="blog-details.html">Augustin Kamtchouang</a></li>
                                    <li class="d-flex align-items-center"><i class="bi bi-clock"></i> <a href="blog-details.html"><time datetime="2020-01-01">Okt, 26 2024</time></a></li>
                                    <li class="d-flex align-items-center"><i class="bi bi-chat-dots"></i> <a href="blog-details.html">12 Comments</a></li>
                                </ul>
                            </div>

                            <div class="meta-bottom">
                                <i class="bi bi-folder"></i>
                                <ul class="cats">
                                    <li><a href="#">Machine Learning</a></li>
                                </ul>

                                <i class="bi bi-tags"></i>
                                <ul class="tags">
                                    <li><a href="#">Creative</a></li>
                                    <li><a href="#">Tips</a></li>
                                    <li><a href="#">Marketing</a></li>
                                </ul>
                            </div>
                        </article>
                    </div>
                </section><!-- /Blog Details Section -->


                <!--          &lt;!&ndash; Blog Comments Section &ndash;&gt;-->
                <!--          <section id="blog-comments" class="blog-comments section">-->

                <!--            <div class="container">-->

                <!--              <h4 class="comments-count">8 Comments</h4>-->

                <!--              <div id="comment-1" class="comment">-->
                <!--                <div class="d-flex">-->
                <!--                  <div class="comment-img"><img src="assets/img/blog/comments-1.jpg" alt=""></div>-->
                <!--                  <div>-->
                <!--                    <h5><a href="">Georgia Reader</a> <a href="#" class="reply"><i class="bi bi-reply-fill"></i> Reply</a></h5>-->
                <!--                    <time datetime="2020-01-01">01 Jan,2022</time>-->
                <!--                    <p>-->
                <!--                      Et rerum totam nisi. Molestiae vel quam dolorum vel voluptatem et et. Est ad aut sapiente quis molestiae est qui cum soluta.-->
                <!--                      Vero aut rerum vel. Rerum quos laboriosam placeat ex qui. Sint qui facilis et.-->
                <!--                    </p>-->
                <!--                  </div>-->
                <!--                </div>-->
                <!--              </div>&lt;!&ndash; End comment #1 &ndash;&gt;-->

                <!--              <div id="comment-2" class="comment">-->
                <!--                <div class="d-flex">-->
                <!--                  <div class="comment-img"><img src="assets/img/blog/comments-2.jpg" alt=""></div>-->
                <!--                  <div>-->
                <!--                    <h5><a href="">Aron Alvarado</a> <a href="#" class="reply"><i class="bi bi-reply-fill"></i> Reply</a></h5>-->
                <!--                    <time datetime="2020-01-01">01 Jan,2022</time>-->
                <!--                    <p>-->
                <!--                      Ipsam tempora sequi voluptatem quis sapiente non. Autem itaque eveniet saepe. Officiis illo ut beatae.-->
                <!--                    </p>-->
                <!--                  </div>-->
                <!--                </div>-->

                <!--                <div id="comment-reply-1" class="comment comment-reply">-->
                <!--                  <div class="d-flex">-->
                <!--                    <div class="comment-img"><img src="assets/img/blog/comments-3.jpg" alt=""></div>-->
                <!--                    <div>-->
                <!--                      <h5><a href="">Lynda Small</a> <a href="#" class="reply"><i class="bi bi-reply-fill"></i> Reply</a></h5>-->
                <!--                      <time datetime="2020-01-01">01 Jan,2022</time>-->
                <!--                      <p>-->
                <!--                        Enim ipsa eum fugiat fuga repellat. Commodi quo quo dicta. Est ullam aspernatur ut vitae quia mollitia id non. Qui ad quas nostrum rerum sed necessitatibus aut est. Eum officiis sed repellat maxime vero nisi natus. Amet nesciunt nesciunt qui illum omnis est et dolor recusandae.-->

                <!--                        Recusandae sit ad aut impedit et. Ipsa labore dolor impedit et natus in porro aut. Magnam qui cum. Illo similique occaecati nihil modi eligendi. Pariatur distinctio labore omnis incidunt et illum. Expedita et dignissimos distinctio laborum minima fugiat.-->

                <!--                        Libero corporis qui. Nam illo odio beatae enim ducimus. Harum reiciendis error dolorum non autem quisquam vero rerum neque.-->
                <!--                      </p>-->
                <!--                    </div>-->
                <!--                  </div>-->

                <!--                  <div id="comment-reply-2" class="comment comment-reply">-->
                <!--                    <div class="d-flex">-->
                <!--                      <div class="comment-img"><img src="assets/img/blog/comments-4.jpg" alt=""></div>-->
                <!--                      <div>-->
                <!--                        <h5><a href="">Sianna Ramsay</a> <a href="#" class="reply"><i class="bi bi-reply-fill"></i> Reply</a></h5>-->
                <!--                        <time datetime="2020-01-01">01 Jan,2022</time>-->
                <!--                        <p>-->
                <!--                          Et dignissimos impedit nulla et quo distinctio ex nemo. Omnis quia dolores cupiditate et. Ut unde qui eligendi sapiente omnis ullam. Placeat porro est commodi est officiis voluptas repellat quisquam possimus. Perferendis id consectetur necessitatibus.-->
                <!--                        </p>-->
                <!--                      </div>-->
                <!--                    </div>-->

                <!--                  </div>&lt;!&ndash; End comment reply #2&ndash;&gt;-->

                <!--                </div>&lt;!&ndash; End comment reply #1&ndash;&gt;-->

                <!--              </div>&lt;!&ndash; End comment #2&ndash;&gt;-->


                <!--            </div>-->

                <!--          </section>&lt;!&ndash; /Blog Comments Section &ndash;&gt;-->

                <!--          comment section-->
            </div>

            <div class="col-lg-4 sidebar">

                <div class="widgets-container">

                    <!--            &lt;!&ndash; Search Widget &ndash;&gt;-->
                    <!--            <div class="search-widget widget-item">-->

                    <!--              <h3 class="widget-title">Search</h3>-->
                    <!--              <form action="">-->
                    <!--                <input type="text">-->
                    <!--                <button type="submit" title="Search"><i class="bi bi-search"></i></button>-->
                    <!--              </form>-->

                    <!--            </div>&lt;!&ndash;/Search Widget &ndash;&gt;-->

                    <!--            &lt;!&ndash; Categories Widget &ndash;&gt;-->
                    <!--            <div class="categories-widget widget-item">-->

                    <!--              <h3 class="widget-title">Categories</h3>-->
                    <!--              <ul class="mt-3">-->
                    <!--                <li><a href="#">General <span>(25)</span></a></li>-->
                    <!--                <li><a href="#">Lifestyle <span>(12)</span></a></li>-->
                    <!--                <li><a href="#">Travel <span>(5)</span></a></li>-->
                    <!--                <li><a href="#">Design <span>(22)</span></a></li>-->
                    <!--                <li><a href="#">Creative <span>(8)</span></a></li>-->
                    <!--                <li><a href="#">Educaion <span>(14)</span></a></li>-->
                    <!--              </ul>-->

                    <!--            </div>&lt;!&ndash;/Categories Widget &ndash;&gt;-->

                    <!-- Recent Posts Widget -->
                    <div class="recent-posts-widget widget-item">

                        <h3 class="widget-title">Recent Posts</h3>


                        <div class="post-item">
                            <img src="assets/img/blog/blog-chatGPT.jpg" alt="" class="flex-shrink-0">
                            <div>
                                <h4><a href="blog-details.html">Natural Language Processing Pipeline</a></h4>
                                <time datetime="2020-01-01">Okt 26, 2024</time>
                            </div>
                        </div><!-- End recent post item-->

                        <div class="post-item">
                            <img src="assets/img/blog/blog-artificial-brain.jpg" alt="" class="flex-shrink-0">
                            <div>
                                <h4><a href="blog-details-2.html">Künstliche Neuronale Netze</a></h4>
                                <time datetime="2020-01-01">Okt 28, 2024</time>
                            </div>
                        </div><!-- End recent post item-->

                    </div><!--/Recent Posts Widget -->

                    <!--            &lt;!&ndash; Tags Widget &ndash;&gt;-->
                    <!--            <div class="tags-widget widget-item">-->

                    <!--              <h3 class="widget-title">Tags</h3>-->
                    <!--              <ul>-->
                    <!--                <li><a href="#">App</a></li>-->
                    <!--                <li><a href="#">IT</a></li>-->
                    <!--                <li><a href="#">Business</a></li>-->
                    <!--                <li><a href="#">Mac</a></li>-->
                    <!--                <li><a href="#">Design</a></li>-->
                    <!--                <li><a href="#">Office</a></li>-->
                    <!--                <li><a href="#">Creative</a></li>-->
                    <!--                <li><a href="#">Studio</a></li>-->
                    <!--                <li><a href="#">Smart</a></li>-->
                    <!--                <li><a href="#">Tips</a></li>-->
                    <!--                <li><a href="#">Marketing</a></li>-->
                    <!--              </ul>-->

                    <!--            </div>&lt;!&ndash;/Tags Widget &ndash;&gt;-->

                </div>

            </div>

        </div>
    </div>

    <!--Calendly Modal Popup-->
    <div id="myModal" class="modal">
        <div class="modal-content">
            <span class="close">&times;</span>
            <div class="calendly-inline-widget" data-url="https://calendly.com/juniorkamtchouang/introductory-meeting"
                 style="min-width:320px;height:630px;"></div>
        </div>


    </div>

</main>

<footer id="footer" class="footer dark-background">

    <div class="container footer-top">
        <div class="row gy-4">
            <div class="col-lg-4 col-md-6 footer-about">
                <a href="index.html" class="logo d-flex align-items-center">
                    <span class="sitename">Little Big Web</span>
                </a>
                <div class="footer-contact pt-3">
                    <p class="mt-3"><strong>Phone:</strong> <span><a href="tel: +491789815652">+49 178 981565 2</a></span></p>
                    <p><strong>Email:</strong> <span><a href="mailto: juniorkamtchouang@outlook.de">juniorkamtchouang@outlook.de</a></span></p>
                </div>
            </div>


            <div class="col-lg-2 col-md-3 footer-links">
                <h4>Our Services</h4>
                <ul>
                    <li><a href="service-details.html#service-details">Web Design</a></li>
                    <li><a href="service-details.html#software-development-content">Software Entwicklung</a></li>
                    <li><a href="service-details.html#product-management-content">Produkt Management</a></li>
                    <li><a href="service-details.html#digital-marketing-content">Digitale Marketing</a></li>
                    <li><a href="service-details.html#graphic-design-content">Graphic Design</a></li>
                </ul>
            </div>


        </div>
    </div>

    <div class="container copyright text-center mt-4">
        <p>© <span>Copyright</span> <strong class="px-1 sitename">Little Big Web</strong> <span>All Rights Reserved</span></p>

    </div>

</footer>

<!-- Scroll Top -->
<a href="#" id="scroll-top" class="scroll-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

<!-- Preloader -->
<div id="preloader"></div>

<!-- Vendor JS Files -->
<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="assets/vendor/php-email-form/validate.js"></script>
<script src="assets/vendor/aos/aos.js"></script>
<script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
<script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
<script src="assets/vendor/imagesloaded/imagesloaded.pkgd.min.js"></script>
<script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
<script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

<!-- Main JS File -->
<script src="assets/js/main.js"></script>
<script type="text/javascript" src="https://assets.calendly.com/assets/external/widget.js" async></script>


</body>

</html>